{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alphabet Soup Deep Learning Model Report\n",
    "## Overview\n",
    "The purpose of this report is to record the performance of the deep learning model trained to analyze applicants to the non-profit foundation Alphabet Soup and identify whether they have a high chance of success if funded. Data collected of previous funding recipients and their success was used to train the model.\n",
    "\n",
    "## Results\n",
    "As seen below, the model after optimization was able to achieve 73% accuracy, which is a marginal increase from 72.7% pre-optimization.\n",
    "\n",
    "PRE-OPTIMIZATION:\n",
    "![Alt text](image-1.png)\n",
    "OPTIMIZED:\n",
    "![Alt text](image.png)\n",
    "\n",
    "### Data Preprocessing\n",
    "The target for this model is found in the charity_data.csv file column IS_SUCCESSFUL, which indicated whether a funding recipient was successful, while the features for this model include various data points about the applicant such as applicant income amount, how much money they applied for, whether the applicant was independent or a part of an organization, and so on. Identifiable information such as applicant name and EIN that was neither a target nor feature was removed.\n",
    "\n",
    "### Compiling, Training, and Evaluating the Model\n",
    "2 hidden layers were selected for this model, with the first having 80 neurons and the second having 30, and a rectified linear unit activation function was used. During the optimization, various combinations of hidden layers (ranging from 2-3) with various amounts of neurons (ranging from 30-80) and differing numbers of epochs (ranging from 80-132) were tested in an attempt to increase accuracy.\n",
    "\n",
    "Through testing, target model performance of over 75% was not achieved. Aside from adjusting hidden layers, neurons, and epochs, an additional bin was created for more rare occurences. This, however, did not have a significant impact on performance.\n",
    "\n",
    "\n",
    "## Summary\n",
    "While this model did not reach target performance, further time could be dedicated to optimize. Specifically analyzing the effects of various activation functions and dropping more columns in preprocessing may yield successful results. \n",
    "\n",
    "Alternatively, a logistic regression model may be trained to predict the success of applicants. A logistic regression model would have the benefit of higher explainability and give us a better idea of how the model is classifying applicants.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
